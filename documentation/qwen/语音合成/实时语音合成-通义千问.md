title: 实时语音合成-通义千问
update: 2025-11-18
source: https://help.aliyun.com/zh/model-studio/qwen-tts-realtime

# 实时语音合成-通义千问

实时语音合成-通义千问提供低延迟、流式文本输入与流式音频输出能力，提供多种拟人音色，支持多语种/方言合成，可在同一音色下输出多语种，并能自适应调节语气，流畅处理复杂文本。

相较于非实时版本，支持：

- 流式输入文本：可无缝对接大模型流式输出，边生成边合成。
- 双向通信：使用 WebSocket 实现文本流式输入与音频流式输出，降低延迟。

## 支持的模型

- 推荐使用 `Qwen3-TTS Realtime`
- `Qwen3-TTS Realtime` 提供 17 种音色，支持自定义音频格式、采样率、语速、音量、音高、码率。
- `Qwen-TTS Realtime` 提供 7 种音色，语种限于中文和英文，不支持上述自定义参数。

## 访问方式（WebSocket）

- 调用地址：
  - 中国大陆（北京）：`wss://dashscope.aliyuncs.com/api-ws/v1/realtime`
  - 国际（新加坡）：`wss://dashscope-intl.aliyuncs.com/api-ws/v1/realtime`
- 查询参数：`model` 指定访问的模型名称
- 鉴权：`Authorization: Bearer DASHSCOPE_API_KEY`

## 快速开始（Python）

准备运行环境：安装 `pyaudio` 与 WebSocket 依赖。

```python
# macOS
#   brew install portaudio && pip install pyaudio
# Debian/Ubuntu
#   sudo apt-get install python-pyaudio python3-pyaudio
#   or
#   pip install pyaudio
# CentOS
#   sudo yum install -y portaudio portaudio-devel && pip install pyaudio
# Windows
#   python -m pip install pyaudio

pip install websocket-client==1.8.0 websockets
```

建立 WebSocket 连接并实时播放：

```python
# tts_realtime_client.py / server_commit.py 示例，省略连接细节
# 代码需将 session.mode 设置为 "server_commit" 以启用服务端智能分段与合成
# 服务端将以 response.audio.delta 等事件流式返回音频数据
```

## 交互流程（server_commit 模式）

| 阶段 | 客户端事件 | 服务器事件 |
| :--- | :--- | :--- |
| 会话初始化 | `session.update` | `session.created`、`session.updated` |
| 用户文本输入 | `input_text_buffer.append`、`input_text_buffer.commit`、`session.finish` | `input_text_buffer.committed` |
| 服务器音频输出 | — | `response.created`、`response.output_item.added`、`response.content_part.added`、`response.audio.delta`、`response.content_part.done`、`response.output_item.done`、`response.audio.done`、`response.done` |

## API参考与音色

- API 参考：实时语音合成-通义千问 API 参考（文内链接保留原样）
- 支持的音色：文档表格中列出 `voice` 参数、音色效果、描述及支持语种

## 相关链接

- 实时语音合成-CosyVoice/Sambert: ./实时语音合成-CosyVoice/Sambert.md
- 语音合成-通义千问: ./通义千问的语音合成模型.md
- 产品详情: [产品详情](https://www.aliyun.com/product/bailian) [来源]