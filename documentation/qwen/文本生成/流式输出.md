---
title: 流式输出
update: 2025-11-06
source: https://help.aliyun.com/zh/model-studio/stream
---

在实时聊天或长文本生成应用中，长时间的等待会损害用户体验并可能导致触发服务端超时，导致任务失败。流式输出通过持续返回模型生成的文本片段，解决了这两个核心问题。

## 工作原理

流式输出基于 Server-Sent Events (SSE) 协议。发起流式请求后，服务端与客户端建立持久化 HTTP 连接。模型每生成一个文本块（称为 chunk），立即通过连接推送。全部内容生成后，服务端发送结束信号。

客户端监听事件流，实时接收并处理文本块，例如逐字渲染界面。这与非流式调用（一次性返回所有内容）形成对比。

## 计费说明

流式输出计费规则与非流式调用完全相同，根据请求的输入Token数和输出Token数计费。

请求中断时，输出 Token 仅计算服务端收到终止请求前已生成的部分。

## 如何使用

重要
Qwen3 开源版、QwQ 商业版与开源版、QVQ 、Qwen-Omni等模型仅支持流式输出方式调用。

### 步骤一：配置 API Key 并选择地域

需要已获取API Key并配置API Key到环境变量。
将API Key配置为环境变量（`DASHSCOPE_API_KEY`）比在代码中硬编码更安全。

### 步骤二：发起流式请求（OpenAI 兼容）

```python
import os
from openai import OpenAI

# 1. 准备工作：初始化客户端
client = OpenAI(
    api_key=os.environ["DASHSCOPE_API_KEY"],
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# 2. 发起流式请求
completion = client.chat.completions.create(
    model="qwen-plus",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "请介绍一下自己"}
    ],
    stream=True,
    stream_options={"include_usage": True}
)

# 3. 处理流式响应
content_parts = []
print("AI: ", end="", flush=True)

for chunk in completion:
    if chunk.choices:
        content = chunk.choices[0].delta.content or ""
        print(content, end="", flush=True)
        content_parts.append(content)
    elif chunk.usage:
        print("\n--- 请求用量 ---")
        print(f"输入 Tokens: {chunk.usage.prompt_tokens}")
        print(f"输出 Tokens: {chunk.usage.completion_tokens}")
        print(f"总计 Tokens: {chunk.usage.total_tokens}")

full_response = "".join(content_parts)
```

```javascript
import OpenAI from "openai";

async function main() {
    if (!process.env.DASHSCOPE_API_KEY) {
        throw new Error("请设置环境变量 DASHSCOPE_API_KEY");
    }
    const client = new OpenAI({
        apiKey: process.env.DASHSCOPE_API_KEY,
        baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1",
    });

    const stream = await client.chat.completions.create({
        model: "qwen-plus",
        messages: [
            { role: "system", content: "You are a helpful assistant." },
            { role: "user", content: "请介绍一下自己" },
        ],
        stream: true,
        stream_options: { include_usage: true },
    });

    const contentParts = [];
    process.stdout.write("AI: ");
    for await (const chunk of stream) {
        if (chunk.choices && chunk.choices.length > 0) {
            const content = chunk.choices[0]?.delta?.content || "";
            process.stdout.write(content);
            contentParts.push(content);
        } else if (chunk.usage) {
            console.log("\n--- 请求用量 ---");
            console.log(`输入 Tokens: ${chunk.usage.prompt_tokens}`);
            console.log(`输出 Tokens: ${chunk.usage.completion_tokens}`);
            console.log(`总计 Tokens: ${chunk.usage.total_tokens}`);
        }
    }
}

main();
```

## 多模态模型的流式输出

```python
from openai import OpenAI
import os

client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

completion = client.chat.completions.create(
    model="qwen3-vl-plus",
    messages=[
        {"role": "user",
         "content": [{"type": "image_url",
                       "image_url": {"url": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241022/emyrja/dog_and_girl.jpeg"}},
                      {"type": "text", "text": "图中描绘的是什么景象？"}]}],
    stream=True,
)

full_content = ""
print("流式输出内容为：")
for chunk in completion:
    if chunk.choices and chunk.choices[0].delta.content != "":
        full_content += chunk.choices[0].delta.content
        print(chunk.choices[0].delta.content)
print(f"完整内容为：{full_content}")
```

```javascript
import OpenAI from "openai";

const openai = new OpenAI({
    apiKey: process.env.DASHSCOPE_API_KEY,
    baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1"
});

const completion = await openai.chat.completions.create({
    model: "qwen3-vl-plus",
    messages: [
        {role: "user",
        content: [{"type": "image_url",
                    "image_url": {"url": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241022/emyrja/dog_and_girl.jpeg"}},
                    {"type": "text", "text": "图中描绘的是什么景象？"}]}],
    stream: true,
});

let fullContent = ""
console.log("流式输出内容为：")
for await (const chunk of completion) {
    if (chunk.choices[0] && chunk.choices[0].delta.content != null) {
      fullContent += chunk.choices[0].delta.content;
      console.log(chunk.choices[0].delta.content);
    }
}
console.log(`完整输出内容为：${fullContent}`)
```