---
title: 批量推理
update: 2025-11-06
source: https://help.aliyun.com/zh/model-studio/batch-inference
---

批量推理（Batch API）用于异步处理大量请求，成本约为实时推理的 50%，适合模型评测、数据标注等场景。

## 工作流程

1. 提交任务：上传包含多个请求的 JSONL 文件并创建任务
2. 异步处理：系统后台处理队列中的请求
3. 下载结果：完成后生成成功结果文件与错误文件（如有）

## 输入规范

- 格式：UTF-8 编码的 JSONL（每行一个 JSON 对象）
- 规模：单文件 ≤ 50,000 行，≤ 500 MB；单行 ≤ 6 MB
- 一致性：同一文件内必须使用相同模型与思考模式
- 唯一标识：每行需包含唯一的 `custom_id`

## OpenAI 兼容接口流程

- 创建任务：`POST /v1/batches`
- 轮询状态：`GET /v1/batches/{batch_id}`，当 `status=completed` 记录 `output_file_id`
- 下载结果：`GET /v1/files/{output_file_id}/content`

## 计费说明

- 成功请求的输入与输出 Token 按实时价格的 50% 计费
- 仅对成功执行的请求计费；解析失败或行级错误不计费

## 常见问题

- 立即失败（failed）：通常为文件级错误（格式、规模、模型一致性）
- 处理时长：受系统负载影响，确保“最长等待时间”设置合理