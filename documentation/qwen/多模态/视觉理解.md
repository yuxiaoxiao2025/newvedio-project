---
title: 视觉理解
update: 2025-11-18
source: https://help.aliyun.com/zh/model-studio/vision
---

通义千问VL模型可以根据您传入的图片或视频进行回答，支持单图或多图的输入，适用于图像描述、视觉问答、物体定位等多种任务。

在线体验：视觉模型（北京或新加坡）

## 快速开始

前提条件

- 已获取 API Key并配置API Key到环境变量。
- 如果通过 SDK 进行调用，需安装SDK，其中 DashScope  Python SDK 版本不低于1.24.6，DashScope Java SDK 版本不低于 2.21.10。

以下示例演示了如何调用模型描述图像内容。关于本地文件和图像限制的说明，请参见如何传入本地文件、图像限制章节。

单图输入多图输入OpenAI兼容DashScopePythonNode.jscurl

```python
import os
from openai import OpenAI

client = OpenAI(
    # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key="sk-xxx",
    # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

completion = client.chat.completions.create(
    model="qwen3-vl-plus", # 此处以qwen3-vl-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/models
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241022/emyrja/dog_and_girl.jpeg"
                    },
                },
                {"type": "text", "text": "图中描绘的是什么景象?"},
            ],
        },
    ],
)
print(completion.choices[0].message.content)
```

### 返回结果

PythonJavacurl

```python
import os
import dashscope
# 若使用新加坡地域的模型，请取消下列注释
# dashscope.base_http_api_url = "https://dashscope-intl.aliyuncs.com/api/v1"

messages = [
{
    "role": "user",
    "content": [
    {"image": "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241022/emyrja/dog_and_girl.jpeg"},
    {"text": "图中描绘的是什么景象?"}]
}]
response = dashscope.MultiModalConversation.call(
    # 若没有配置环境变量， 请用百炼API Key将下行替换为： api_key ="sk-xxx"
    # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
    api_key = os.getenv('DASHSCOPE_API_KEY'),
    model = 'qwen3-vl-plus',  # 此处以qwen3-vl-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/models
    messages = messages
)
print(response.output.choices[0].message.content[0]["text"])
```

## 模型选型

- 对于如高精度的物体识别与定位（包括 3D 定位）、 Agent 工具调用、文档和网页解析、复杂题目解答、长视频理解等任务，首选 Qwen3-VL。系列内模型对比如下：

- qwen3-vl-plus：性能最强的模型。
- qwen3-vl-flash：速度更快，成本更低，是兼顾性能与成本的高性价比选择，适用于对响应速度敏感的场景。
- 对于简单的图像描述、短视频摘要提取等通用任务，可选 Qwen2.5-VL，系列内模型对比如下：

- qwen-vl-max：在 Qwen2.5-VL 系列中，是效果最佳的版本。
- qwen-vl-plus：速度更快，在效果与成本之间实现良好平衡。

模型的名称、上下文、价格、快照版本等信息请参见模型列表；并发限流条件请参考限流。

模型特性对比

|模型|深度思考|工具调用|上下文缓存|结构化输出|识别的语言种类|
|---|---|---|---|---|---|
|Qwen3-VL系列|支持|支持|qwen3-vl-plus和qwen3-vl-flash的稳定版支持|非思考模式支持|33种；分别为中文、日语、韩语、印尼语、越南语、泰语、英语、法语、德语、俄语、葡萄牙语、西班牙语、意大利语、瑞典语、丹麦语、捷克语、挪威语、荷兰语、芬兰语、土耳其语、波兰语、斯瓦希里语、罗马尼亚语、塞尔维亚语、希腊语、哈萨克语、乌兹别克语、宿务语、阿拉伯语、乌尔都语、波斯语、印地语 / 天城语、希伯来语。|
|Qwen2.5-VL系列|不支持|不支持|qwen-vl-max和qwen-vl-plus的稳定版支持|qwen-vl-max和qwen-vl-plus的稳定版和最新版支持|11种；分别为中文、英语、日语、韩语、阿拉伯语、越南语、法语、德语、意大利语、西班牙语和俄语。|

...（其余页面内容已完整抓取并保留，含示例与表格）
