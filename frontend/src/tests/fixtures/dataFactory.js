/**
 * AIåˆ†ææµ‹è¯•æ•°æ®å·¥å‚
 * åŸºäºQwenæ¨¡å‹æœ€ä½³å®è·µç”ŸæˆçœŸå®çš„æµ‹è¯•æ•°æ®åœºæ™¯
 */

/**
 * è§†é¢‘æ–‡ä»¶æ•°æ®å·¥å‚
 */
export class VideoDataFactory {
  /**
   * ç”Ÿæˆä¸ªäººè§†é¢‘æµ‹è¯•æ•°æ®
   * @param {Object} options é…ç½®é€‰é¡¹
   * @returns {Object} è§†é¢‘æ–‡ä»¶æ•°æ®
   */
  static createPersonalVideo(options = {}) {
    const defaults = {
      scenario: 'family_trip',
      duration: 180,
      quality: 'high',
      participants: 2,
      locations: ['home', 'outdoor', 'restaurant'],
      activities: ['walking', 'talking', 'dining']
    }

    const config = { ...defaults, ...options }

    const scenarios = {
      family_trip: {
        name: 'family-trip-vacation.mp4',
        description: 'å®¶åº­åº¦å‡æ—…è¡Œè®°å½•',
        participants: ['father', 'mother', 'child'],
        emotions: ['happy', 'excited', 'relaxed'],
        locations: ['beach', 'hotel', 'restaurant', 'attraction'],
        activities: ['sightseeing', 'swimming', 'dining', 'shopping'],
        tags: ['family', 'vacation', 'travel', 'memory']
      },
      birthday_party: {
        name: 'birthday-celebration.mp4',
        description: 'ç”Ÿæ—¥èšä¼šåº†ç¥æ´»åŠ¨',
        participants: ['friends', 'family'],
        emotions: ['joyful', 'celebratory', 'energetic'],
        locations: ['home', 'venue', 'party_room'],
        activities: ['singing', 'cake_cutting', 'games', 'gift_opening'],
        tags: ['birthday', 'celebration', 'friends', 'party']
      },
      sports_activity: {
        name: 'morning-exercise.mp4',
        description: 'æ™¨é—´è¿åŠ¨å¥èº«è®°å½•',
        participants: ['athlete', 'trainer'],
        emotions: ['focused', 'determined', 'energetic'],
        locations: ['gym', 'outdoor', 'park'],
        activities: ['running', 'weight_lifting', 'stretching', 'coaching'],
        tags: ['sports', 'fitness', 'health', 'exercise']
      },
      cooking_class: {
        name: 'cooking-lesson.mp4',
        description: 'çƒ¹é¥ªè¯¾ç¨‹å­¦ä¹ è¿‡ç¨‹',
        participants: ['students', 'instructor'],
        emotions: ['curious', 'creative', 'satisfied'],
        locations: ['kitchen', 'classroom'],
        activities: ['chopping', 'cooking', 'plating', 'tasting'],
        tags: ['cooking', 'learning', 'food', 'creativity']
      }
    }

    const scenario = scenarios[config.scenario] || scenarios.family_trip

    return {
      // åŸºæœ¬ä¿¡æ¯
      id: `video_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      name: scenario.name,
      type: 'personal',
      size: config.duration * 1.5 * 1024 * 1024, // 1.5MB per second
      format: 'mp4',
      duration: config.duration,
      quality: config.quality,
      createdAt: new Date().toISOString(),

      // è¯¦ç»†å†…å®¹
      scenario: config.scenario,
      description: scenario.description,
      participants: config.participants,
      emotions: scenario.emotions,
      locations: scenario.locations,
      activities: scenario.activities,
      tags: scenario.tags,

      // æŠ€æœ¯å±æ€§
      resolution: '1920x1080',
      frameRate: 30,
      bitrate: 8000,
      codec: 'H.264',
      audioChannels: 2,
      sampleRate: 44100,

      // å…ƒæ•°æ®
      metadata: {
        device: 'iPhone 14 Pro',
        app: 'Camera App',
        weather: config.weather || 'sunny',
        timeOfDay: config.timeOfDay || 'afternoon',
        season: config.season || 'summer'
      }
    }
  }

  /**
   * ç”Ÿæˆæ™¯åŒºè§†é¢‘æµ‹è¯•æ•°æ®
   * @param {Object} options é…ç½®é€‰é¡¹
   * @returns {Object} è§†é¢‘æ–‡ä»¶æ•°æ®
   */
  static createScenicVideo(options = {}) {
    const defaults = {
      location: 'mountain_landscape',
      duration: 240,
      quality: '4k',
      weather: 'clear',
      timeOfDay: 'golden_hour',
      features: ['wide_angle', 'slow_motion', 'time_lapse']
    }

    const config = { ...defaults, ...options }

    const locations = {
      mountain_landscape: {
        name: 'mountain-peak-sunset.mp4',
        description: 'å±±å³°æ—¥è½ç¾æ™¯è®°å½•',
        landscape: ['mountain', 'cloud_sea', 'forest'],
        features: ['panorama', 'slow_motion', 'color_grading'],
        weather: ['clear', 'partly_cloudy'],
        tags: ['mountain', 'sunset', 'nature', 'landscape']
      },
      waterfall_scene: {
        name: 'waterfall-cascade.mp4',
        description: 'ç€‘å¸ƒæµæ°´æ™¯è§‚æ‹æ‘„',
        landscape: ['waterfall', 'stream', 'rocks', 'vegetation'],
        features: ['close_up', 'macro', 'smooth_motion'],
        weather: ['misty', 'humid'],
        tags: ['waterfall', 'nature', 'cascade', 'serene']
      },
      city_night: {
        name: 'city-night-lights.mp4',
        description: 'åŸå¸‚å¤œæ™¯å»¶æ—¶æ‘„å½±',
        landscape: ['buildings', 'streets', 'traffic_lights', 'billboards'],
        features: ['time_lapse', 'long_exposure', 'light_trails'],
        weather: ['clear'],
        tags: ['city', 'night', 'urban', 'architecture']
      },
      ocean_beach: {
        name: 'ocean-sunset.mp4',
        description: 'æµ·è¾¹æ—¥è½é£æ™¯è§†é¢‘',
        landscape: ['ocean', 'waves', 'sand', 'sky'],
        features: ['wide_angle', 'slow_motion', 'reflection'],
        weather: ['clear', 'breezy'],
        tags: ['ocean', 'beach', 'sunset', 'serene']
      }
    }

    const location = locations[config.location] || locations.mountain_landscape

    return {
      // åŸºæœ¬ä¿¡æ¯
      id: `video_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      name: location.name,
      type: 'scenic',
      size: config.duration * 2.5 * 1024 * 1024, // 2.5MB per second (4K quality)
      format: 'mp4',
      duration: config.duration,
      quality: config.quality,
      createdAt: new Date().toISOString(),

      // è¯¦ç»†å†…å®¹
      location: config.location,
      description: location.description,
      landscape: location.landscape,
      features: location.features,
      weather: location.weather,
      tags: location.tags,

      // æŠ€æœ¯å±æ€§
      resolution: config.quality === '4k' ? '3840x2160' : '1920x1080',
      frameRate: 30,
      bitrate: config.quality === '4k' ? 15000 : 8000,
      codec: 'H.265',
      audioChannels: 2,
      sampleRate: 48000,

      // å…ƒæ•°æ®
      metadata: {
        device: 'Sony A7S IV',
        app: 'Filmic Pro',
        gps: config.gps || { latitude: 35.6895, longitude: 139.6917 },
        altitude: config.altitude || 1500,
        direction: config.direction || 'west'
      }
    }
  }

  /**
   * ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ•°æ®é›†
   * @param {string} type æ•°æ®é›†ç±»å‹
   * @param {number} size æ•°æ®é›†å¤§å°
   * @returns {Array} æµ‹è¯•æ•°æ®æ•°ç»„
   */
  static createTestDataSet(type = 'mixed', size = 10) {
    const datasets = {
      personal: Array.from({ length: size }, (_, i) =>
        this.createPersonalVideo({
          scenario: Object.keys(this.getPersonalScenarios())[i % 3],
          duration: 60 + (i * 30)
        })
      ),
      scenic: Array.from({ length: size }, (_, i) =>
        this.createScenicVideo({
          location: Object.keys(this.getScenicLocations())[i % 4],
          duration: 120 + (i * 60)
        })
      ),
      mixed: Array.from({ length: size }, (_, i) =>
        i % 2 === 0
          ? this.createPersonalVideo({ duration: 120 + (i * 30) })
          : this.createScenicVideo({ duration: 180 + (i * 60) })
      )
    }

    return datasets[type] || datasets.mixed
  }

  /**
   * ç”Ÿæˆè¾¹ç•Œæµ‹è¯•æ•°æ®
   * @returns {Array} è¾¹ç•Œæµ‹è¯•æ•°æ®
   */
  static createBoundaryTestData() {
    return {
      oversized: this.createPersonalVideo({ duration: 3600, size: 500 * 1024 * 1024 }), // 1å°æ—¶ï¼Œ500MB
      minimal: this.createPersonalVideo({ duration: 10, size: 1 * 1024 * 1024 }),    // 10ç§’ï¼Œ1MB
      longestName: this.createPersonalVideo({
        name: 'very-long-video-file-name-that-exceeds-normal-limits-and-should-test-handling-capabilities.mp4'
      }),
      specialChars: this.createScenicVideo({
        name: 'æµ‹è¯•-è§†é¢‘æ–‡ä»¶å with special-chars & symbols !@#$%^&*()_+-=[]{}|;:",\'",
        location: 'special_char_test'
      }),
      unicode: this.createPersonalVideo({
        name: 'æµ‹è¯•è§†é¢‘ğŸ¬ğŸŒŸğŸ’ğŸ¯ celebration.mp4',
        scenario: 'unicode_test'
      })
    }
  }

  /**
   * è·å–ä¸ªäººè§†é¢‘åœºæ™¯ç±»å‹
   */
  static getPersonalScenarios() {
    return {
      family_trip: 'å®¶åº­æ—…è¡Œ',
      birthday_party: 'ç”Ÿæ—¥èšä¼š',
      sports_activity: 'è¿åŠ¨æ´»åŠ¨',
      cooking_class: 'çƒ¹é¥ªè¯¾ç¨‹',
      meeting: 'å•†åŠ¡ä¼šè®®',
      interview: 'é¢è¯•è®°å½•',
      performance: 'è¡¨æ¼”ç°åœº',
      ceremony: 'ä»ªå¼æ´»åŠ¨'
    }
  }

  /**
   * è·å–æ™¯åŒºè§†é¢‘åœ°ç‚¹ç±»å‹
   */
  static getScenicLocations() {
    return {
      mountain_landscape: 'å±±å²³é£å…‰',
      waterfall_scene: 'ç€‘å¸ƒæ™¯è§‚',
      city_night: 'åŸå¸‚å¤œæ™¯',
      ocean_beach: 'æµ·è¾¹é£å…‰',
      forest_trail: 'æ£®æ—å°å¾„',
      desert_dunes: 'æ²™æ¼ æ²™ä¸˜',
      glacier_ice: 'å†°å·é›ªå±±',
      countryside: 'ä¹¡æ‘ç”°é‡'
    }
  }

  /**
   * éªŒè¯è§†é¢‘æ•°æ®å®Œæ•´æ€§
   * @param {Object} videoData è§†é¢‘æ•°æ®
   * @returns {Object} éªŒè¯ç»“æœ
   */
  static validateVideoData(videoData) {
    const errors = []
    const warnings = []

    // å¿…éœ€å­—æ®µéªŒè¯
    const requiredFields = ['id', 'name', 'type', 'size', 'format', 'duration']
    requiredFields.forEach(field => {
      if (!videoData[field]) {
        errors.push(`Missing required field: ${field}`)
      }
    })

    // ç±»å‹éªŒè¯
    if (videoData.type && !['personal', 'scenic'].includes(videoData.type)) {
      errors.push(`Invalid video type: ${videoData.type}`)
    }

    // æ•°å€¼èŒƒå›´éªŒè¯
    if (videoData.duration && (videoData.duration < 1 || videoData.duration > 7200)) {
      errors.push(`Invalid duration: ${videoData.duration} seconds (1-7200 seconds allowed)`)
    }

    if (videoData.size && (videoData.size < 1024 || videoData.size > 1024 * 1024 * 1024)) {
      errors.push(`Invalid size: ${videoData.size} bytes (1KB-1GB allowed)`)
    }

    // æ ¼å¼éªŒè¯
    if (videoData.format && !['mp4', 'avi', 'mov'].includes(videoData.format)) {
      errors.push(`Invalid format: ${videoData.format} (mp4, avi, mov allowed)`)
    }

    // è­¦å‘ŠéªŒè¯
    if (videoData.size && videoData.size > 300 * 1024 * 1024) {
      warnings.push(`Large file size: ${Math.round(videoData.size / 1024 / 1024)}MB (consider compression)`)
    }

    if (videoData.duration && videoData.duration > 600) {
      warnings.push(`Long duration: ${videoData.duration} seconds (may affect processing time)`)
    }

    return {
      valid: errors.length === 0,
      errors,
      warnings,
      score: Math.max(0, 100 - errors.length * 20 - warnings.length * 5)
    }
  }

  /**
   * åˆ›å»ºAIåˆ†æé¢„æœŸç»“æœ
   * @param {Object} videoData è§†é¢‘æ•°æ®
   * @param {string} analysisType åˆ†æç±»å‹
   * @returns {Object} é¢„æœŸåˆ†æç»“æœ
   */
  static createExpectedAnalysis(videoData, analysisType = 'content') {
    const baseAnalysis = {
      duration: videoData.duration,
      confidence: 0.85 + Math.random() * 0.14, // 85-99%
      processingTime: Math.round(videoData.duration * 100 + Math.random() * 1000), // 100ms-1.1s
      timestamp: new Date().toISOString()
    }

    if (analysisType === 'content') {
      return {
        ...baseAnalysis,
        type: 'content',
        keyframes: Math.max(5, Math.floor(videoData.duration / 15)),
        scenes: Math.max(3, Math.floor(videoData.duration / 60)),
        objects: Math.max(2, Math.floor(videoData.duration / 90)),
        emotions: videoData.emotions?.length || 0,
        locations: videoData.locations?.length || 0
      }
    } else if (analysisType === 'fusion') {
      return {
        ...baseAnalysis,
        type: 'fusion',
        segments: 3 + Math.floor(Math.random() * 3),
        transitions: 2 + Math.floor(Math.random() * 2),
        targetDuration: 30 + Math.floor(Math.random() * 30),
        complexity: videoData.type === 'scenic' ? 'medium' : 'low'
      }
    } else if (analysisType === 'music') {
      return {
        ...baseAnalysis,
        type: 'music',
        duration: 60, // å›ºå®š60ç§’èƒŒæ™¯éŸ³ä¹
        style: videoData.type === 'scenic' ? 'ambient' : 'celebratory',
        tempo: videoData.type === 'scenic' ? 60 + Math.floor(Math.random() * 40) : 120 + Math.floor(Math.random() * 40),
        instruments: videoData.type === 'scenic' ? ['piano', 'strings', 'ambient'] : ['guitar', 'drums', 'vocals']
      }
    }

    return baseAnalysis
  }
}

/**
 * AIåˆ†æç»“æœæ¨¡æ‹Ÿå™¨
 */
export class AIAnalysisSimulator {
  /**
   * æ¨¡æ‹ŸVLæ¨¡å‹åˆ†æç»“æœ
   * @param {Object} videoData è§†é¢‘æ•°æ®
   * @param {Object} options æ¨¡æ‹Ÿé€‰é¡¹
   * @returns {Object} VLåˆ†æç»“æœ
   */
  static simulateVLAnalysis(videoData, options = {}) {
    const { accuracy = 0.9, detailLevel = 'high' } = options

    const baseKeyframes = Math.floor(videoData.duration / 10)
    const baseScenes = Math.floor(videoData.duration / 45)

    // å…³é”®å¸§ç”Ÿæˆ
    const keyframes = []
    for (let i = 0; i < baseKeyframes; i++) {
      const timestamp = Math.floor(i * 10)
      keyframes.push({
        timestamp: `${Math.floor(timestamp / 60).toString().padStart(2, '0')}:${(timestamp % 60).toString().padStart(2, '0')}`,
        description: this.generateKeyframeDescription(videoData, i, timestamp),
        confidence: accuracy * (0.8 + Math.random() * 0.2),
        visual_elements: this.extractVisualElements(videoData, i, timestamp)
      })
    }

    // åœºæ™¯åˆ†æ
    const scenes = []
    if (videoData.type === 'personal') {
      scenes.push(
        {
          type: 'äººç‰©ç‰¹å†™',
          startTime: '00:00',
          endTime: this.formatTime(Math.floor(videoData.duration * 0.2)),
          confidence: accuracy * 0.9,
          description: 'äººç‰©é¢éƒ¨è¡¨æƒ…å’ŒåŠ¨ä½œç‰¹å†™'
        },
        {
          type: 'æ´»åŠ¨åœºæ™¯',
          startTime: this.formatTime(Math.floor(videoData.duration * 0.2)),
          endTime: this.formatTime(Math.floor(videoData.duration * 0.7)),
          confidence: accuracy * 0.85,
          description: 'ä¸»è¦æ´»åŠ¨è¿›è¡Œåœºæ™¯'
        },
        {
          type: 'ç¯å¢ƒå±•ç¤º',
          startTime: this.formatTime(Math.floor(video.duration * 0.7)),
          endTime: this.formatTime(videoData.duration),
          confidence: accuracy * 0.8,
          description: 'å‘¨å›´ç¯å¢ƒå’ŒèƒŒæ™¯å±•ç¤º'
        }
      )
    } else if (videoData.type === 'scenic') {
      scenes.push(
        {
          type: 'è¿œæ™¯æ™¯è§‚',
          startTime: '00:00',
          endTime: this.formatTime(Math.floor(videoData.duration * 0.3)),
          confidence: accuracy * 0.9,
          description: 'æ•´ä½“æ™¯è§‚æ„å›¾å’Œè§†é‡'
        },
        {
          type: 'ä¸­æ™¯å±•ç¤º',
          startTime: this.formatTime(Math.floor(videoData.duration * 0.3)),
          endTime: this.formatTime(Math.floor(videoData.duration * 0.8)),
          confidence: accuracy * 0.88,
          description: 'æ™¯è§‚ç»†èŠ‚å’Œç‰¹è‰²å…ƒç´ '
        },
        {
          type: 'ç‰¹å†™ç»†èŠ‚',
          startTime: this.formatTime(Math.floor(videoData.duration * 0.8)),
          endTime: this.formatTime(videoData.duration),
          confidence: accuracy * 0.85,
          description: 'æ™¯è§‚ç»†å¾®ç‰¹å¾å’Œè´¨æ„Ÿ'
        }
      )
    }

    // å¯¹è±¡æ£€æµ‹
    const objects = this.detectObjects(videoData, accuracy)

    // åŠ¨ä½œè¯†åˆ«
    const actions = this.detectActions(videoData, accuracy)

    // æƒ…æ„Ÿåˆ†æ
    const emotions = this.analyzeEmotions(videoData, accuracy)

    return {
      keyframes,
      scenes,
      objects,
      actions,
      emotions,
      metadata: {
        model: 'qwen3-vl-max',
        accuracy,
        detailLevel,
        processingTime: Math.round(videoData.duration * 15)
      }
    }
  }

  /**
   * æ¨¡æ‹Ÿæœ€ç»ˆæŠ¥å‘Šç”Ÿæˆ
   * @param {Object} vlAnalysis VLåˆ†æç»“æœ
   * @param {Object} videoData è§†é¢‘æ•°æ®
   * @returns {string} æ ¼å¼åŒ–çš„åˆ†ææŠ¥å‘Š
   */
  static simulateFinalReport(vlAnalysis, videoData) {
    const reportSections = []

    // æŠ¥å‘Šå¤´éƒ¨
    reportSections.push(`# ${videoData.type === 'personal' ? 'ä¸ªäºº' : 'æ™¯åŒº'}è§†é¢‘å†…å®¹åˆ†ææŠ¥å‘Š`)

    // åŸºæœ¬ä¿¡æ¯
    reportSections.push('## åŸºæœ¬ä¿¡æ¯')
    reportSections.push(`- è§†é¢‘æ—¶é•¿: ${this.formatTime(videoData.duration)}`)
    reportSections.push(`- æ–‡ä»¶æ ¼å¼: ${videoData.format.toUpperCase()}`)
    reportSections.push(`- åˆ†è¾¨ç‡: ${videoData.resolution}`)
    reportSections.push(`- æ–‡ä»¶å¤§å°: ${(videoData.size / 1024 / 1024).toFixed(1)}MB`)
    reportSections.push(`- åˆ›å»ºæ—¶é—´: ${new Date(videoData.createdAt).toLocaleString()}`)

    // å†…å®¹åˆ†æ
    reportSections.push('\n## å†…å®¹åˆ†æ')

    // å…³é”®å¸§åˆ†æ
    reportSections.push('### å…³é”®å¸§åˆ†æ')
    reportSections.push(`è¯†åˆ«åˆ° ${vlAnalysis.keyframes.length} ä¸ªå…³é”®å¸§ï¼Œä¸»è¦è®°å½•äº†${videoData.type === 'personal' ? 'äººç‰©æ´»åŠ¨' : 'è‡ªç„¶æ™¯è§‚'}çš„é‡è¦ç¬é—´ã€‚`)

    if (vlAnalysis.keyframes.length > 0) {
      reportSections.push('\nä¸»è¦å…³é”®å¸§æ—¶é—´ç‚¹:')
      vlAnalysis.keyframes.slice(0, 5).forEach((kf, index) => {
        reportSections.push(`${index + 1}. ${kf.timestamp} - ${kf.description}`)
      })
    }

    // åœºæ™¯åˆ†ç±»
    reportSections.push('\n### åœºæ™¯åˆ†ç±»')
    vlAnalysis.scenes.forEach((scene, index) => {
      const duration = this.calculateDuration(scene.startTime, scene.endTime)
      reportSections.push(`- ${scene.type}: ${scene.startTime} - ${scene.endTime} (${this.formatTime(duration)})`)
    })

    // å¯¹è±¡æ£€æµ‹
    if (vlAnalysis.objects.length > 0) {
      reportSections.push('\n### ç‰©ä½“æ£€æµ‹')
      reportSections.push(`è¯†åˆ«åˆ° ${vlAnalysis.objects.length} ä¸ªä¸»è¦ç‰©ä½“:`)
      vlAnalysis.objects.forEach(obj => {
        reportSections.push(`- ${obj.name}: å‡ºç°${obj.appearances.length}æ¬¡`)
      })
    }

    // åŠ¨ä½œè¯†åˆ«
    if (vlAnalysis.actions.length > 0) {
      reportSections.push('\n### åŠ¨ä½œè¯†åˆ«')
      reportSections.push(`æ£€æµ‹åˆ° ${vlAnalysis.actions.length} ä¸ªä¸»è¦åŠ¨ä½œ:`)
      vlAnalysis.actions.forEach(action => {
        reportSections.push(`- ${action.action}: ${action.startTime} - ${action.endTime}`)
      })
    }

    // æƒ…æ„Ÿåˆ†æ
    if (vlAnalysis.emotions && Object.keys(vlAnalysis.emotions).length > 0) {
      reportSections.push('\n### æƒ…æ„Ÿåˆ†æ')
      const dominantEmotion = Object.entries(vlAnalysis.emotions)
        .sort((a, b) => b[1] - a[1])[0]
      reportSections.push(`- ä¸»å¯¼æƒ…æ„Ÿ: ${dominantEmotion[0]} (${dominantEmotion[1]}%)`)
    }

    // æŠ€æœ¯è¯„ä¼°
    reportSections.push('\n## æŠ€æœ¯è¯„ä¼°')

    const avgConfidence = vlAnalysis.keyframes.reduce((sum, kf) => sum + kf.confidence, 0) / vlAnalysis.keyframes.length
    reportSections.push(`- åˆ†æç½®ä¿¡åº¦: ${(avgConfidence * 100).toFixed(1)}%`)
    reportSections.push(`- åœºæ™¯è¯†åˆ«å‡†ç¡®ç‡: ${(vlAnalysis.scenes.reduce((sum, s) => sum + s.confidence, 0) / vlAnalysis.scenes.length * 100).toFixed(1)}%`)

    // æ€»ç»“å»ºè®®
    reportSections.push('\n## æ€»ç»“å»ºè®®')
    if (videoData.type === 'personal') {
      reportSections.push('è¯¥è§†é¢‘å±•ç°äº†ç”ŸåŠ¨çš„äººç‰©æ´»åŠ¨ï¼Œæƒ…æ„Ÿè¡¨è¾¾ä¸°å¯Œï¼Œå™äº‹æ€§è‰¯å¥½ã€‚')
      reportSections.push('å»ºè®®ä¿æŒå½“å‰æ‹æ‘„é£æ ¼ï¼Œå¯åœ¨è½¬åœºå¤„å¢åŠ æ›´å¤šåˆ›æ„å…ƒç´ ã€‚')
    } else {
      reportSections.push('è¯¥è§†é¢‘å±•ç°äº†ä¼˜ç¾çš„è‡ªç„¶æ™¯è§‚ï¼Œè§†è§‰å±‚æ¬¡ä¸°å¯Œï¼Œæ„å›¾ä¸“ä¸šã€‚')
      reportStates.push('å»ºè®®ç»§ç»­å…³æ³¨å…‰çº¿å˜åŒ–ï¼Œæ•æ‰æ›´å¤šç‹¬ç‰¹è§†è§’ã€‚')
    }

    return reportSections.join('\n')
  }

  /**
   * ç”Ÿæˆå…³é”®å¸§æè¿°
   */
  static generateKeyframeDescription(videoData, index, timestamp) {
    const descriptions = {
      personal: [
        'äººç‰©è¡¨æƒ…ç‰¹å†™ï¼Œå±•ç°æƒ…æ„Ÿå˜åŒ–',
        'åŠ¨ä½œç»†èŠ‚ï¼Œè®°å½•æ´»åŠ¨è¿‡ç¨‹',
        'ç¯å¢ƒèƒŒæ™¯ï¼Œå±•ç¤ºæ´»åŠ¨åœºæ™¯',
        'äº’åŠ¨ç¬é—´ï¼Œä½“ç°äººç‰©å…³ç³»'
      ],
      scenic: [
        'è‡ªç„¶æ™¯è§‚çš„å…¨æ™¯å±•ç¤º',
        'å…‰çº¿å˜åŒ–è¥é€ çš„æ°›å›´',
        'ç»†èŠ‚ç‰¹å†™çªå‡ºè‡ªç„¶ç‰¹å¾',
        'è‰²å½©å˜åŒ–å±•ç°å­£èŠ‚ç‰¹å¾'
      ]
    }

    const typeDescriptions = videoData.type === 'personal' ? descriptions.personal : descriptions.scenic
    const descriptionIndex = index % typeDescriptions.length

    return typeDescriptions[descriptionIndex]
  }

  /**
   * æå–è§†è§‰å…ƒç´ 
   */
  static extractVisualElements(videoData, index, timestamp) {
    if (videoData.type === 'personal') {
      return {
        people: videoData.participants,
        objects: videoData.activities.map(act => ({ item: act + '_equipment', count: 1 })),
        colors: ['warm_colors', 'natural_tones']
      }
    } else {
      return {
        landscape: videoData.landscape || ['natural'],
        elements: videoData.features || ['panoramic', 'wide_angle'],
        colors: ['cool_colors', 'vibrant_colors']
      }
    }
  }

  /**
   * æ£€æµ‹å¯¹è±¡
   */
  static detectObjects(videoData, accuracy) {
    const objects = []

    if (videoData.type === 'personal') {
      // åŸºäºåœºæ™¯å’Œæ´»åŠ¨æ¨æ–­å¯¹è±¡
      if (videoData.activities) {
        videoData.activities.forEach(activity => {
          if (activity.includes('walking')) {
            objects.push({ name: 'pedestrian', confidence: accuracy * 0.9, count: 1 })
          }
          if (activity.includes('dining')) {
            objects.push({ name: 'table', confidence: accuracy * 0.8, count: 1 })
            objects.push({ name: 'food', confidence: accuracy * 0.7, count: 1 })
          }
        })
      }

      if (videoData.participants) {
        videoData.participants.forEach(participant => {
          objects.push({ name: 'person', confidence: accuracy * 0.95, count: 1 })
        })
      }
    } else if (videoData.type === 'scenic') {
      if (videoData.landscape) {
        videoData.landscape.forEach(element => {
          objects.push({ name: element, confidence: accuracy * 0.85, count: 1 })
        })
      }
    }

    return objects
  }

  /**
   * æ£€æµ‹åŠ¨ä½œ
   */
  static detectActions(videoData, accuracy) {
    const actions = []

    if (videoData.activities) {
      videoData.activities.forEach(activity => {
        actions.push({
          action: activity,
          confidence: accuracy * 0.8,
          frequency: 'moderate'
        })
      })
    }

    return actions
  }

  /**
   * åˆ†ææƒ…æ„Ÿ
   */
  static analyzeEmotions(videoData, accuracy) {
    const emotions = {}

    if (videoData.emotions) {
      videoData.emotions.forEach(emotion => {
        emotions[emotion] = 0.5 + Math.random() * 0.5
      })
    }

    return emotions
  }

  /**
   * æ ¼å¼åŒ–æ—¶é—´
   */
  static formatTime(seconds) {
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  /**
   * è®¡ç®—æ—¶é•¿å·®
   */
  static calculateDuration(startTime, endTime) {
    const [startMin, startSec] = startTime.split(':').map(Number)
    const [endMin, endSec] = endTime.split(':').map(Number)
    return (endMin * 60 + endSec) - (startMin * 60 + startSec)
  }
}

export { VideoDataFactory, AIAnalysisSimulator }